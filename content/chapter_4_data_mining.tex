\chapter{Data Mining}
\label{cha:data_mining}
\begin{itemize}
	\item Input: Preprocessed Data
	\item Output: Model / Patterns
\end{itemize}

\begin{enumerate}
	\item Apply data mining method
	\item Evaluate resulting model / patterns (using P, R, F1, not accuracy)
	\item Iterate:
	\begin{itemize}
		\item Experiment with different parameter settings
		\item Experiment with different alternative methods – Improve preprocessing and feature generation – Combine different methods
	\end{itemize}
\end{enumerate}

\section{Algorithms}
To predict the success of a movie different Algorithms were used:
\begin{itemize}
	\item K-Nearest Neighbor
	\item Naive Bayes
	\item Support Vector Classifier
	\item Neural Net
	\item \textbf{Decision Tree}
	\item \textbf{Random Forest}
\end{itemize}
The following analysis concentrates on the three algorithms with the best results: Random Forest, Decision Tree and Support Vector Classifier.
The first goal of the analysis was to predict the success in five different classes. Since an analysis in that detail with the given dataset is very unprecise, an binary classifier was created. In the following results for the multiclass prediction as well as for the binary prediction will be presented. To find the best parameter setting , a gridsearch in combination with a ten-fold cross-validation, scoring the highest F1-score, was applied for each of the classifier.

\subsection{Decision Tree}
SOMETHING ABOUT MULTICLASS HERE.
Regarding the binary classifier, predicting if a movie is going to be a success, the dataset is unbalanced with a proximate ratio of 75\% "succesfull" and 25\% "unsuccessfull". Most of the classifier give bad results with unbalanced datasets. But especially tree-structures can handle unbalanced datasets well, since the hierarchical structure allows them to learn signals from both classes.
The parameters for the Gridsearch tested the split criterion Entropy and Gini, the max-depth of the tree and the minimum of samples to split. 
With this setting the decision tree achieves an F1 score of 56\% (macro) and 75.5\% (micro).
Since scoring the F1-micro only predicts successfull, downsampling was used, to improve the prediction. Tuples of the majority class were removed to have a balance of 50/50.
With downsampling the tree scores 61.9\% (macro) and 63.0\% (micro). The downsampling improved the macro score, so the tree does not only predict "successfull". Since the downsampled dataset is probably too small to learn a good classifier, the next step to improve the algorithm is to upsample the dataset. WRITE REST FOR UPSAMPLING HERE

\subsection{Random Forest}
Random Forest builds like the decsion tree a hierarchical structure, which can handle unbalanced datasets better than other algorithms. In addition it corrects the overfitting habit of a decision tree. In the gridsearch hyperparameters like the split-criterion, number of features, the minimum sample to split and wheather bootstrap samples are used or not are evaluated.
With the best parametersetting the algorithm scores in the ten-fold cross-validation 58.7\% (macro) and 76.0\% (micro).
With a downsampled dataset the algroithm scores 80.6\% (macro) and 81.5\% (micro).
SOMETHING ABOUT UPSAMPLING HERE:

\subsection{Support Vector Classifier}

\section{Three best performing algorithms}
\begin{itemize}
	\item Pick best three algos
	\item GridSearch
	\item Why does each classifier perform how it performs (unausgeglichene Klassen, ...)?
\end{itemize}
